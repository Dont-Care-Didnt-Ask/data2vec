{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "146fa837",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a809edef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=5\n",
      "env: OMP_NUM_THREADS=8\n",
      "env: MKL_NUM_THREADS=8\n"
     ]
    }
   ],
   "source": [
    "## Choose appropriate GPU\n",
    "%env CUDA_VISIBLE_DEVICES=5\n",
    "%env OMP_NUM_THREADS=8\n",
    "%env MKL_NUM_THREADS=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e9bfd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from data import Data2VecDataset\n",
    "\n",
    "train_dataset = Data2VecDataset('/mnt/data/imagenet/train')\n",
    "val_dataset = Data2VecDataset('/mnt/data/imagenet/val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0768deea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data2vec_collate_fn(samples):\n",
    "    imgs, masks = zip(*samples)\n",
    "    return dict(pixel_values=torch.stack(imgs), bool_masked_pos=torch.stack(masks))\n",
    "\n",
    "batch_size = 256\n",
    "num_workers = 16\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size, collate_fn=data2vec_collate_fn, num_workers=num_workers)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size, collate_fn=data2vec_collate_fn, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66610391",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vit_data2vec import ViTForData2Vec, ViTConfigForData2Vec\n",
    "\n",
    "config = ViTConfigForData2Vec(\n",
    "    # data2vec hyperparams\n",
    "    n_layers_to_average=8,\n",
    "    huber_loss_delta=2.0,\n",
    "    \n",
    "    # ViT-B hyperparams\n",
    "    hidden_size=768, \n",
    "    num_hidden_layers=12,\n",
    "    num_attention_heads=12,\n",
    "    intermediate_size=3072,\n",
    "    hidden_act=\"gelu\",\n",
    "    hidden_dropout_prob=0.0,\n",
    "    attention_probs_dropout_prob=0.0,\n",
    "    initializer_range=0.02,\n",
    "    layer_norm_eps=1e-12,\n",
    "    is_encoder_decoder=False,\n",
    "    image_size=224,\n",
    "    patch_size=16,\n",
    "    num_channels=3,\n",
    "    qkv_bias=True,\n",
    "    encoder_stride=16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f64f4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb537954",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ViTForData2Vec(config).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3753e2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.Adam(model.student.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f288d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "466ab161",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "addcmul() received an invalid combination of arguments - got (), but expected (Tensor input, Tensor tensor1, Tensor tensor2, *, Number value, Tensor out)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1183/3309368959.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: addcmul() received an invalid combination of arguments - got (), but expected (Tensor input, Tensor tensor1, Tensor tensor2, *, Number value, Tensor out)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.addcmul()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442fcc4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c06d537b12b45a491111354b2941dc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e2a6091ff1949a886d7e2ffa8b0bf0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batch:   0%|          | 0/5005 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9203659296035767\n",
      "0.27822282910346985\n",
      "0.09442088007926941\n",
      "0.0766567587852478\n",
      "0.09168350696563721\n",
      "0.06233667582273483\n",
      "0.056215494871139526\n",
      "0.18188852071762085\n",
      "0.05987240746617317\n",
      "0.059019941836595535\n",
      "0.04463276267051697\n",
      "0.0398867204785347\n",
      "0.03693309798836708\n",
      "0.03414800390601158\n",
      "0.07123082131147385\n",
      "0.04626847803592682\n",
      "0.0409870445728302\n",
      "0.030353739857673645\n",
      "0.01685752160847187\n",
      "0.031272247433662415\n",
      "0.029573682695627213\n",
      "0.026683809235692024\n",
      "0.02493894100189209\n",
      "0.03403769060969353\n",
      "0.026136333122849464\n",
      "0.02686288207769394\n",
      "0.027769921347498894\n",
      "0.02693517506122589\n",
      "0.029408009722828865\n",
      "0.03125990182161331\n",
      "0.02900662086904049\n",
      "0.024813253432512283\n",
      "0.02809232473373413\n",
      "0.023744763806462288\n",
      "0.022244183346629143\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 5\n",
    "momentum = 0.9998\n",
    "update_freq = 4\n",
    "log_freq = 40\n",
    "\n",
    "for epoch in tqdm(range(n_epochs), desc='Epoch'):\n",
    "    for step, batch in enumerate(tqdm(train_loader, desc='Batch', leave=False)):\n",
    "        batch['pixel_values'] = batch['pixel_values'].to(device)\n",
    "        batch['bool_masked_pos'] = batch['bool_masked_pos'].to(device)\n",
    "        \n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss        \n",
    "        loss.backward()\n",
    "        \n",
    "        if step % update_freq == 0:\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "            \n",
    "            model.update_teacher(momentum)\n",
    "        \n",
    "        if step % log_freq == 0:\n",
    "            print(loss.item())\n",
    "            \n",
    "            # Could look at the distribution of output entries\n",
    "            #plt.hist(outputs.prediction.detach().cpu().numpy().ravel(), alpha=0.3)\n",
    "            #plt.hist(outputs.target.detach().cpu().numpy().ravel(), alpha=0.3)\n",
    "            #plt.ylabel('Frequency')\n",
    "            #plt.xlabel('Output value')\n",
    "            #plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
